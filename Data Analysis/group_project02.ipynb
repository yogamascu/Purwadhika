{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group-2\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "---\n",
    "\n",
    "X-mart is our team’s latest venture and after running international operations for his online supermarket that specialises in fresh produce. The founder is asking for your support to analyse his sales performance. In June 2020, large-scale supply changes were made at Data Mart. All Data Mart products now use sustainable packaging methods in every single step from the farm all the way to the customer.\n",
    "\n",
    "The founder needs your help to quantify the impact of this change on the sales performance for Data Mart and it’s separate business areas. The key business question he wants you to help him answer is the following:\n",
    "\n",
    "- What was the quantifiable impact of the changes introduced in June 2020?\n",
    "- Which platform, region, segment, and customer types were the most impacted by this change?\n",
    "- What can we do about the future introduction of similar sustainability updates to the business to minimize the impact on sales?\n",
    "\n",
    "## Avaliable Data\n",
    "\n",
    "---\n",
    "\n",
    "For this case study there is only a single table `weekly_sales`. The columns are pretty self-explanatory based on the column names but here are some further details about the dataset:\n",
    "\n",
    "1. Data Mart has international operations using a multi-`region` strategy\n",
    "2. Data Mart has both, a retail and online `platform` in the form of a Shopify store front to serve their customers\n",
    "3. Customer `segment` and `customer_type` data relates to personal age and demographics information that is shared with Data Mart\n",
    "4. `transactions` is the count of unique purchases made through Data Mart and `sales` is the actual dollar amount of purchases\n",
    "\n",
    "Each record in the dataset is related to a specific aggregated slice of the underlying sales data rolled up into a `week_date` value which represents the start of the sales week.\n",
    "\n",
    "**Link to download data:**\n",
    "\n",
    "https://drive.google.com/drive/folders/1pprpd4NbbZ_gBfccCjAqbhF0aJKtoMI9?usp=share_link\n",
    "\n",
    "## Case Study Questions\n",
    "\n",
    "---\n",
    "\n",
    "The following case study questions require some data cleaning steps before we start to unpack key business questions in more depth. In a single query, perform the following operations and generate a new table in the `data_mart` schema named `clean_weekly_sales`:\n",
    "\n",
    "1. Convert the week_date to a DATE format.\n",
    "2. Add a week_number as the second column for each `week_date` value, for example any value from the 1st of January to 7th of January will be 1, 8th to 14th will be 2 etc.\n",
    "3. Add a `month_number` with the calendar month for each `week_date` value as the 3rd column.\n",
    "4. Add a `calendar_year` column as the 4th column containing either 2018, 2019 or 2020 values.\n",
    "5. Add a new column called `age_band` after the original `segment` column using the following mapping on the number inside the `segment` value:\n",
    "    \n",
    "    \n",
    "    | segment | age_band |\n",
    "    | --- | --- |\n",
    "    | 1 | Young Adults |\n",
    "    | 2 | Middle Aged |\n",
    "    | 3 or 4 | Retirees |\n",
    "6. Add a new `demographic` column using the following mapping for the first letter in the `segment` values:\n",
    "    \n",
    "    \n",
    "    | segment | demographic |\n",
    "    | --- | --- |\n",
    "    | C | Couples |\n",
    "    | F | Families |\n",
    "7. Ensure all `null` string values with an `\"unknown\"` string value in the original `segment` column as well as the new `age_band` and `demographic` columns\n",
    "8. Generate a new `avg_transaction` column as the `sales` value divided by `transactions` rounded to 2 decimal places for each record\n",
    "\n",
    "### Question 1: **Data Exploration**\n",
    "\n",
    "1. What day of the week is used for each `week_date` value?\n",
    "2. What range of week numbers are missing from the dataset?\n",
    "3. How many total transactions were there for each year in the dataset?\n",
    "4. What is the total sales for each region for each month?\n",
    "5. What is the total count of transactions for each platform\n",
    "6. Which `age_band` and `demographic` values contribute the most to Retail sales?\n",
    "7. Can we use the `avg_transaction` column to find the average transaction size for each year for Retail vs Shopify? If not - how would you calculate it instead?\n",
    "\n",
    "### Question 2: **Before & After Analysis**\n",
    "\n",
    "This technique is usually used when we inspect an important event and want to inspect the impact before and after a certain point in time. \n",
    "\n",
    "Taking the `week_date` value of `2020-06-15` as the baseline week where the Data Mart sustainable packaging changes came into effect. We would include all `week_date` values for `2020-06-15` as the start of the period **after** the change and the previous `week_date` values would be **before.** \n",
    "\n",
    "Using this analysis approach - answer the following questions:\n",
    "\n",
    "1. What is the total sales for the 4 weeks before and after `2020-06-15`? What is the growth or reduction rate in actual values and percentage of sales?\n",
    "2. What about the entire 12 weeks before and after?\n",
    "3. How do the sale metrics for these 2 periods before and after compare with the previous years in 2018 and 2019?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector \n",
    "import pandas as pd\n",
    "def show(db, query):\n",
    "    con = mysql.connector.connect(\n",
    "        host = 'localhost',\n",
    "        user = 'root',\n",
    "        passwd = '12345Maskcu',\n",
    "        database = db\n",
    "    )\n",
    "    \n",
    "    executor = con.cursor()\n",
    "    executor.execute(query)\n",
    "    \n",
    "    table = executor.fetchall()\n",
    "    \n",
    "    con.close()\n",
    "    return pd.DataFrame(data=table, columns=executor.column_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
